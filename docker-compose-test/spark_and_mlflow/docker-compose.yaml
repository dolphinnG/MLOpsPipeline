services:

  ############## USE THE POSTGRESQL OF THE KEYCLOAK-LDAP DOCKER-COMPOSE ##############
  # PostgreSQL database
  postgresql:
    image: postgres:latest
    environment:
      POSTGRES_USER: bn_keycloak
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: mlflowdb
    ports:
      - 5432:5432
    # volumes:
    #   - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - shared_network

  redis-cache:
    image: docker.io/bitnami/redis:7.4
    volumes:
      - 'redis_data:/bitnami'
    ports:
      - '6376:6379'
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    networks:
      - shared_network


  # MinIO server
  minio:
    image: minio/minio
    ports:
      - "9900:9000"
      - "9901:9001"
    environment:
      MINIO_ROOT_USER: "minio_user"
      MINIO_ROOT_PASSWORD: "minio_password"
    healthcheck:
      test: timeout 5s bash -c ':> /dev/tcp/127.0.0.1/9000' || exit 1
      interval: 1s
      timeout: 10s
      retries: 5
    command: server /data --console-address ":9001"
    networks:
      - shared_network

  # Create buckets named "mlflow" and "project_logs" if they don't exist
  minio-create-bucket:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      bash -c "
      mc alias set minio http://minio:9000 minio_user minio_password &&
      if ! mc ls minio | grep --quiet mlflow; then
        mc mb minio/mlflow
      else
        echo 'mlflow already exists'
      fi &&
      if ! mc ls minio | grep --quiet projectlogs; then
        mc mb minio/projectlogs
      else
        echo 'projectlogs already exists'
      fi
      "
    networks:
      - shared_network

  # MLflow tracking server
  mlflow:
    image: bitnami/mlflow:latest
    volumes:
      - mlflow-data:/app
    depends_on:
      postgresql:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      # BACKEND_STORE_URI: postgresql://user:password@postgres/mlflowdb
      AWS_ACCESS_KEY_ID: minio_user
      AWS_SECRET_ACCESS_KEY: minio_password
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    ports:
      - "5000:5000"
    entrypoint: mlflow server --backend-store-uri postgresql://bn_keycloak:admin@postgresql/mlflowdb --default-artifact-root s3://mlflow --host 0.0.0.0 --port 5000
    networks:
      - shared_network

  # Spark Master
  spark-master:
    image: supahakka/dolphin-spark:with-username
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minio_user
      - AWS_SECRET_ACCESS_KEY=minio_password
    ports:
      - "880:8080"
      - "7077:7077"
    volumes:
      - spark-master-data:/bitnami/spark
      - ./:/opt/bitnami/spark/testapp
      - spark-shared-data:/opt/bitnami/spark/tmp
    networks:
      - shared_network

  # Spark Worker
  spark-worker:
    # image: bitnami/spark:latest
    image: supahakka/dolphin-spark:with-username
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - MLFLOW_TRACKING_URI=http://mlflow:5000 
      # THE ENV-NAME=URL, THE URL MUST NOT BE IN QUOTES,
      # MEANING NO "http://mlflow:5000" BUT http://mlflow:5000
      # OTHERWISE THE SPARK WORKER WILL NOT BE ABLE TO CONNECT TO THE MLFLOW SERVER
      # IT WILL CAUSE EXCEPTION LIKE: PERMISSION DENIED '"HTTP:
      # AND YOU GET FUCKED @@
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minio_user
      - AWS_SECRET_ACCESS_KEY=minio_password
    depends_on:
      - spark-master
    volumes:
      - spark-worker-data:/bitnami/spark
      - ./:/opt/bitnami/spark/testapp
      - spark-shared-data:/opt/bitnami/spark/tmp
    networks:
      - shared_network

  spark-worker2:
    image: supahakka/dolphin-spark:with-username
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minio_user
      - AWS_SECRET_ACCESS_KEY=minio_password
    depends_on:
      - spark-master
    volumes:
      - spark-worker-data:/bitnami/spark
      - ./:/opt/bitnami/spark/testapp
      - spark-shared-data:/opt/bitnami/spark/tmp
    networks:
      - shared_network

  spark-mlflow-run:
    image: supahakka/mlflow-run:v5
    environment:

      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minio_user
      - AWS_SECRET_ACCESS_KEY=minio_password
    depends_on:
      - spark-master
    volumes:
      - ./:/opt/bitnami/spark/testapp
      - spark-shared-data:/opt/bitnami/spark/tmp
    networks:
      - shared_network

volumes:
  # postgres-data:
  spark-shared-data:
  mlflow-data:
  spark-master-data:
  spark-worker-data:
  redis_data:

networks:
  shared_network:
    external: true